{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec2f3073",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ceebd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'data': array([[5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [5.1, 3.5, 1.4, 0.3],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [6.8, 3. , 5.5, 2.1],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [6.7, 3.3, 5.7, 2.1],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [7.2, 3. , 5.8, 1.6],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5.9, 3. , 5.1, 1.8]]), 'target': array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
      "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2]), 'frame': None, 'target_names': array(['setosa', 'versicolor', 'virginica'], dtype='<U10'), 'DESCR': '.. _iris_dataset:\\n\\nIris plants dataset\\n--------------------\\n\\n**Data Set Characteristics:**\\n\\n    :Number of Instances: 150 (50 in each of three classes)\\n    :Number of Attributes: 4 numeric, predictive attributes and the class\\n    :Attribute Information:\\n        - sepal length in cm\\n        - sepal width in cm\\n        - petal length in cm\\n        - petal width in cm\\n        - class:\\n                - Iris-Setosa\\n                - Iris-Versicolour\\n                - Iris-Virginica\\n                \\n    :Summary Statistics:\\n\\n    ============== ==== ==== ======= ===== ====================\\n                    Min  Max   Mean    SD   Class Correlation\\n    ============== ==== ==== ======= ===== ====================\\n    sepal length:   4.3  7.9   5.84   0.83    0.7826\\n    sepal width:    2.0  4.4   3.05   0.43   -0.4194\\n    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\\n    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\\n    ============== ==== ==== ======= ===== ====================\\n\\n    :Missing Attribute Values: None\\n    :Class Distribution: 33.3% for each of 3 classes.\\n    :Creator: R.A. Fisher\\n    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\\n    :Date: July, 1988\\n\\nThe famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\\nfrom Fisher\\'s paper. Note that it\\'s the same as in R, but not as in the UCI\\nMachine Learning Repository, which has two wrong data points.\\n\\nThis is perhaps the best known database to be found in the\\npattern recognition literature.  Fisher\\'s paper is a classic in the field and\\nis referenced frequently to this day.  (See Duda & Hart, for example.)  The\\ndata set contains 3 classes of 50 instances each, where each class refers to a\\ntype of iris plant.  One class is linearly separable from the other 2; the\\nlatter are NOT linearly separable from each other.\\n\\n.. topic:: References\\n\\n   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\\n     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\\n     Mathematical Statistics\" (John Wiley, NY, 1950).\\n   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\\n     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\\n   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\\n     Structure and Classification Rule for Recognition in Partially Exposed\\n     Environments\".  IEEE Transactions on Pattern Analysis and Machine\\n     Intelligence, Vol. PAMI-2, No. 1, 67-71.\\n   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\\n     on Information Theory, May 1972, 431-433.\\n   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\\n     conceptual clustering system finds 3 classes in the data.\\n   - Many, many more ...', 'feature_names': ['sepal length (cm)', 'sepal width (cm)', 'petal length (cm)', 'petal width (cm)'], 'filename': 'iris.csv', 'data_module': 'sklearn.datasets.data'}\n",
      ".. _iris_dataset:\n",
      "\n",
      "Iris plants dataset\n",
      "--------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 150 (50 in each of three classes)\n",
      "    :Number of Attributes: 4 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      "        - sepal length in cm\n",
      "        - sepal width in cm\n",
      "        - petal length in cm\n",
      "        - petal width in cm\n",
      "        - class:\n",
      "                - Iris-Setosa\n",
      "                - Iris-Versicolour\n",
      "                - Iris-Virginica\n",
      "                \n",
      "    :Summary Statistics:\n",
      "\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "                    Min  Max   Mean    SD   Class Correlation\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "    sepal length:   4.3  7.9   5.84   0.83    0.7826\n",
      "    sepal width:    2.0  4.4   3.05   0.43   -0.4194\n",
      "    petal length:   1.0  6.9   3.76   1.76    0.9490  (high!)\n",
      "    petal width:    0.1  2.5   1.20   0.76    0.9565  (high!)\n",
      "    ============== ==== ==== ======= ===== ====================\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: 33.3% for each of 3 classes.\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "The famous Iris database, first used by Sir R.A. Fisher. The dataset is taken\n",
      "from Fisher's paper. Note that it's the same as in R, but not as in the UCI\n",
      "Machine Learning Repository, which has two wrong data points.\n",
      "\n",
      "This is perhaps the best known database to be found in the\n",
      "pattern recognition literature.  Fisher's paper is a classic in the field and\n",
      "is referenced frequently to this day.  (See Duda & Hart, for example.)  The\n",
      "data set contains 3 classes of 50 instances each, where each class refers to a\n",
      "type of iris plant.  One class is linearly separable from the other 2; the\n",
      "latter are NOT linearly separable from each other.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - Fisher, R.A. \"The use of multiple measurements in taxonomic problems\"\n",
      "     Annual Eugenics, 7, Part II, 179-188 (1936); also in \"Contributions to\n",
      "     Mathematical Statistics\" (John Wiley, NY, 1950).\n",
      "   - Duda, R.O., & Hart, P.E. (1973) Pattern Classification and Scene Analysis.\n",
      "     (Q327.D83) John Wiley & Sons.  ISBN 0-471-22361-1.  See page 218.\n",
      "   - Dasarathy, B.V. (1980) \"Nosing Around the Neighborhood: A New System\n",
      "     Structure and Classification Rule for Recognition in Partially Exposed\n",
      "     Environments\".  IEEE Transactions on Pattern Analysis and Machine\n",
      "     Intelligence, Vol. PAMI-2, No. 1, 67-71.\n",
      "   - Gates, G.W. (1972) \"The Reduced Nearest Neighbor Rule\".  IEEE Transactions\n",
      "     on Information Theory, May 1972, 431-433.\n",
      "   - See also: 1988 MLC Proceedings, 54-64.  Cheeseman et al\"s AUTOCLASS II\n",
      "     conceptual clustering system finds 3 classes in the data.\n",
      "   - Many, many more ...\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "iris_data=load_iris()\n",
    "print(iris_data)\n",
    "print(iris_data['DESCR'])\n",
    "# the output is dictionary\n",
    "# Key is 2D array\n",
    "# Value is 1D array\n",
    "#[5.1, 3.5, 1.4, 0.2] one data of one flower type \n",
    "# example sepal length (5.1) , sepal width(3.5)  and petal length(1.4) , petal width(0.2)\n",
    "# in Value(Target) array 0->setosa , 1->versicolor , 2->virginica\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bef4763c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 4) (150,)\n"
     ]
    }
   ],
   "source": [
    "# store 'data' into X and 'traget' into Y\n",
    "X,Y=iris_data['data'],iris_data['target']\n",
    "# to find the shape of data set (iris data)\n",
    "print(X.shape,Y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4f9d2887",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['setosa']\n"
     ]
    }
   ],
   "source": [
    "#1. Data Gathering\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "#2. Data Pre processing (Not required because iris data is cleaned data)\n",
    "\n",
    "#3. Choose an Algo/Build a model ( we used KNeighborsClassifier)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Load the Data (iris data)\n",
    "iris_data=load_iris()\n",
    "X,Y=iris_data['data'],iris_data['target']\n",
    "\n",
    "knn=KNeighborsClassifier(n_neighbors=4,weights=\"distance\",algorithm=\"ball_tree\") \n",
    "# but the default n_neighbors=5,weights=uniform\n",
    "\n",
    "#4. Train your model (here we used fit())\n",
    "knn.fit(X,Y)\n",
    "\n",
    "#5. Evaluating /Testing our model (we used predict())\n",
    "print(iris_data[\"target_names\"][knn.predict([[3,4,2,3]])])\n",
    "\n",
    "# output : satosa \n",
    "# it means the given input value is belongs to setosa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "85b704a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.9 3.  1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [4.6 3.1 1.5 0.2]]\n",
      "[0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# testing for first four examples of our dataset (iris data set)\n",
    "print(X[:4,:])\n",
    "print(knn.predict(X[:4,:]))\n",
    "#output: first four examples is belongs to zero category (setosa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f4b95ee0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0\n"
     ]
    }
   ],
   "source": [
    "#to calculate the accuracy of our model\n",
    "print(knn.score(X,Y)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cb70c447",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[6.7, 3.3, 5.7, 2.1],\n",
      "       [4.7, 3.2, 1.6, 0.2],\n",
      "       [5. , 3.6, 1.4, 0.2],\n",
      "       [4.4, 3. , 1.3, 0.2],\n",
      "       [4.6, 3.4, 1.4, 0.3],\n",
      "       [5.1, 3.4, 1.5, 0.2],\n",
      "       [5.5, 2.3, 4. , 1.3],\n",
      "       [4.6, 3.1, 1.5, 0.2],\n",
      "       [5.7, 2.8, 4.1, 1.3],\n",
      "       [6.4, 2.7, 5.3, 1.9],\n",
      "       [5.6, 3. , 4.1, 1.3],\n",
      "       [4.9, 3.1, 1.5, 0.2],\n",
      "       [6.2, 2.8, 4.8, 1.8],\n",
      "       [6. , 2.9, 4.5, 1.5],\n",
      "       [4.7, 3.2, 1.3, 0.2],\n",
      "       [6. , 3.4, 4.5, 1.6],\n",
      "       [5.6, 2.8, 4.9, 2. ],\n",
      "       [6.1, 2.9, 4.7, 1.4],\n",
      "       [5.9, 3. , 4.2, 1.5],\n",
      "       [6. , 2.2, 5. , 1.5],\n",
      "       [5. , 3.5, 1.3, 0.3],\n",
      "       [5.6, 3. , 4.5, 1.5],\n",
      "       [4.5, 2.3, 1.3, 0.3],\n",
      "       [6.5, 3. , 5.5, 1.8],\n",
      "       [5.7, 2.6, 3.5, 1. ],\n",
      "       [5.5, 4.2, 1.4, 0.2],\n",
      "       [6.3, 2.3, 4.4, 1.3],\n",
      "       [5. , 2. , 3.5, 1. ],\n",
      "       [6.1, 2.8, 4.7, 1.2],\n",
      "       [5.5, 2.6, 4.4, 1.2],\n",
      "       [6.7, 2.5, 5.8, 1.8],\n",
      "       [6.7, 3. , 5. , 1.7],\n",
      "       [6.3, 2.5, 5. , 1.9],\n",
      "       [5.4, 3.4, 1.5, 0.4],\n",
      "       [6.4, 2.8, 5.6, 2.2],\n",
      "       [5. , 3.4, 1.6, 0.4],\n",
      "       [7.7, 3.8, 6.7, 2.2],\n",
      "       [6.6, 2.9, 4.6, 1.3],\n",
      "       [7.2, 3.2, 6. , 1.8],\n",
      "       [5.5, 2.5, 4. , 1.3],\n",
      "       [6.5, 2.8, 4.6, 1.5],\n",
      "       [6.2, 3.4, 5.4, 2.3],\n",
      "       [5. , 3. , 1.6, 0.2],\n",
      "       [6.3, 2.5, 4.9, 1.5],\n",
      "       [6.7, 3.1, 4.7, 1.5],\n",
      "       [5.4, 3. , 4.5, 1.5],\n",
      "       [6.3, 2.7, 4.9, 1.8],\n",
      "       [5. , 3.4, 1.5, 0.2],\n",
      "       [4.6, 3.6, 1. , 0.2],\n",
      "       [4.9, 3.1, 1.5, 0.1],\n",
      "       [5.7, 2.9, 4.2, 1.3],\n",
      "       [6. , 2.2, 4. , 1. ],\n",
      "       [5. , 3.3, 1.4, 0.2],\n",
      "       [5.5, 3.5, 1.3, 0.2],\n",
      "       [6.7, 3.1, 4.4, 1.4],\n",
      "       [5.2, 3.5, 1.5, 0.2],\n",
      "       [6.9, 3.1, 4.9, 1.5],\n",
      "       [5.4, 3.9, 1.3, 0.4],\n",
      "       [6.9, 3.1, 5.4, 2.1],\n",
      "       [5.1, 3.7, 1.5, 0.4],\n",
      "       [7.4, 2.8, 6.1, 1.9],\n",
      "       [7.7, 3. , 6.1, 2.3],\n",
      "       [7.2, 3.6, 6.1, 2.5],\n",
      "       [5.7, 2.5, 5. , 2. ],\n",
      "       [5.6, 2.5, 3.9, 1.1],\n",
      "       [4.8, 3. , 1.4, 0.3],\n",
      "       [6.7, 3.1, 5.6, 2.4],\n",
      "       [5.1, 3.8, 1.6, 0.2],\n",
      "       [4.8, 3.4, 1.6, 0.2],\n",
      "       [6.4, 3.1, 5.5, 1.8],\n",
      "       [5.8, 2.8, 5.1, 2.4],\n",
      "       [6.5, 3. , 5.8, 2.2],\n",
      "       [5.1, 3.8, 1.9, 0.4],\n",
      "       [6.2, 2.2, 4.5, 1.5],\n",
      "       [5.1, 3.5, 1.4, 0.2],\n",
      "       [4.9, 3.6, 1.4, 0.1],\n",
      "       [6.5, 3.2, 5.1, 2. ],\n",
      "       [5.9, 3. , 5.1, 1.8],\n",
      "       [4.4, 2.9, 1.4, 0.2],\n",
      "       [6.7, 3.3, 5.7, 2.5],\n",
      "       [6.1, 3. , 4.6, 1.4],\n",
      "       [7. , 3.2, 4.7, 1.4],\n",
      "       [6.3, 2.9, 5.6, 1.8],\n",
      "       [7.7, 2.6, 6.9, 2.3],\n",
      "       [6.9, 3.1, 5.1, 2.3],\n",
      "       [7.6, 3. , 6.6, 2.1],\n",
      "       [6.4, 3.2, 5.3, 2.3],\n",
      "       [6.1, 2.6, 5.6, 1.4],\n",
      "       [5.3, 3.7, 1.5, 0.2],\n",
      "       [5.4, 3.4, 1.7, 0.2],\n",
      "       [5.2, 2.7, 3.9, 1.4],\n",
      "       [5.9, 3.2, 4.8, 1.8],\n",
      "       [6.4, 2.9, 4.3, 1.3],\n",
      "       [4.9, 2.5, 4.5, 1.7],\n",
      "       [5.8, 4. , 1.2, 0.2],\n",
      "       [6.3, 3.3, 6. , 2.5],\n",
      "       [6.6, 3. , 4.4, 1.4],\n",
      "       [5.5, 2.4, 3.8, 1.1],\n",
      "       [5.4, 3.9, 1.7, 0.4],\n",
      "       [5.8, 2.6, 4. , 1.2],\n",
      "       [5.4, 3.7, 1.5, 0.2],\n",
      "       [6.8, 3.2, 5.9, 2.3],\n",
      "       [5.7, 3. , 4.2, 1.2],\n",
      "       [4.9, 3. , 1.4, 0.2],\n",
      "       [4.8, 3.4, 1.9, 0.2],\n",
      "       [6.4, 2.8, 5.6, 2.1],\n",
      "       [5. , 3.5, 1.6, 0.6],\n",
      "       [6.1, 3. , 4.9, 1.8],\n",
      "       [5.6, 2.9, 3.6, 1.3],\n",
      "       [7.3, 2.9, 6.3, 1.8],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [5.7, 4.4, 1.5, 0.4],\n",
      "       [7.9, 3.8, 6.4, 2. ],\n",
      "       [5.2, 4.1, 1.5, 0.1],\n",
      "       [5.7, 2.8, 4.5, 1.3],\n",
      "       [6.3, 3.3, 4.7, 1.6],\n",
      "       [4.8, 3.1, 1.6, 0.2],\n",
      "       [5.6, 2.7, 4.2, 1.3],\n",
      "       [6.3, 3.4, 5.6, 2.4],\n",
      "       [5.1, 3.5, 1.4, 0.3]]), array([[6.8, 3. , 5.5, 2.1],\n",
      "       [4.3, 3. , 1.1, 0.1],\n",
      "       [6.2, 2.9, 4.3, 1.3],\n",
      "       [5.1, 3.3, 1.7, 0.5],\n",
      "       [5. , 2.3, 3.3, 1. ],\n",
      "       [5.1, 3.8, 1.5, 0.3],\n",
      "       [4.6, 3.2, 1.4, 0.2],\n",
      "       [5.8, 2.7, 4.1, 1. ],\n",
      "       [6.4, 3.2, 4.5, 1.5],\n",
      "       [6.8, 2.8, 4.8, 1.4],\n",
      "       [6.5, 3. , 5.2, 2. ],\n",
      "       [4.4, 3.2, 1.3, 0.2],\n",
      "       [6.7, 3. , 5.2, 2.3],\n",
      "       [5.8, 2.7, 5.1, 1.9],\n",
      "       [6. , 3. , 4.8, 1.8],\n",
      "       [4.9, 2.4, 3.3, 1. ],\n",
      "       [6. , 2.7, 5.1, 1.6],\n",
      "       [7.1, 3. , 5.9, 2.1],\n",
      "       [6.1, 2.8, 4. , 1.3],\n",
      "       [6.9, 3.2, 5.7, 2.3],\n",
      "       [7.7, 2.8, 6.7, 2. ],\n",
      "       [4.8, 3. , 1.4, 0.1],\n",
      "       [5.2, 3.4, 1.4, 0.2],\n",
      "       [5.7, 3.8, 1.7, 0.3],\n",
      "       [5. , 3.2, 1.2, 0.2],\n",
      "       [5.8, 2.7, 3.9, 1.2],\n",
      "       [5.1, 2.5, 3. , 1.1],\n",
      "       [6.3, 2.8, 5.1, 1.5],\n",
      "       [5.5, 2.4, 3.7, 1. ],\n",
      "       [7.2, 3. , 5.8, 1.6]]), array([2, 0, 0, 0, 0, 0, 1, 0, 1, 2, 1, 0, 2, 1, 0, 1, 2, 1, 1, 2, 0, 1,\n",
      "       0, 2, 1, 0, 1, 1, 1, 1, 2, 1, 2, 0, 2, 0, 2, 1, 2, 1, 1, 2, 0, 1,\n",
      "       1, 1, 2, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 2, 0, 2, 2, 2, 2, 1, 0,\n",
      "       2, 0, 0, 2, 2, 2, 0, 1, 0, 0, 2, 2, 0, 2, 1, 1, 2, 2, 2, 2, 2, 2,\n",
      "       0, 0, 1, 1, 1, 2, 0, 2, 1, 1, 0, 1, 0, 2, 1, 0, 0, 2, 0, 2, 1, 2,\n",
      "       2, 0, 2, 0, 1, 1, 0, 1, 2, 0]), array([2, 0, 1, 0, 1, 0, 0, 1, 1, 1, 2, 0, 2, 2, 2, 1, 1, 2, 1, 2, 2, 0,\n",
      "       0, 0, 0, 1, 1, 2, 1, 2])]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(train_test_split(X,Y,test_size=0.2)) \n",
    "#it return four values that is  x_train,x_test,y_train,y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "835b1e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(120, 4) (120,)\n",
      "(30, 4) (30,)\n"
     ]
    }
   ],
   "source": [
    "# Calculating the shape of x_train,x_test,y_train,y_test\n",
    "x_train,x_test,y_train,y_test=train_test_split(X,Y,test_size=0.2,)\n",
    "print(x_train.shape,y_train.shape)\n",
    "print(x_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5a2f1495",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training accuracy :100.0%\n"
     ]
    }
   ],
   "source": [
    "# calculating the Training accuracy of our model\n",
    "knn.fit(x_train,y_train)\n",
    "print(f\"Training accuracy :{knn.score(x_train,y_train)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ad7b5006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "testing accuracy: 96.66666666666667%\n"
     ]
    }
   ],
   "source": [
    "# calculating the Testing accuracy of our model\n",
    "predict=knn.predict(x_test)\n",
    "print(f\"testing accuracy: {accuracy_score(y_test,predict)*100}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cc885784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class KNeighborsClassifier in module sklearn.neighbors._classification:\n",
      "\n",
      "class KNeighborsClassifier(sklearn.neighbors._base.KNeighborsMixin, sklearn.base.ClassifierMixin, sklearn.neighbors._base.NeighborsBase)\n",
      " |  KNeighborsClassifier(n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |  \n",
      " |  Classifier implementing the k-nearest neighbors vote.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <classification>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  n_neighbors : int, default=5\n",
      " |      Number of neighbors to use by default for :meth:`kneighbors` queries.\n",
      " |  \n",
      " |  weights : {'uniform', 'distance'}, callable or None, default='uniform'\n",
      " |      Weight function used in prediction.  Possible values:\n",
      " |  \n",
      " |      - 'uniform' : uniform weights.  All points in each neighborhood\n",
      " |        are weighted equally.\n",
      " |      - 'distance' : weight points by the inverse of their distance.\n",
      " |        in this case, closer neighbors of a query point will have a\n",
      " |        greater influence than neighbors which are further away.\n",
      " |      - [callable] : a user-defined function which accepts an\n",
      " |        array of distances, and returns an array of the same shape\n",
      " |        containing the weights.\n",
      " |  \n",
      " |  algorithm : {'auto', 'ball_tree', 'kd_tree', 'brute'}, default='auto'\n",
      " |      Algorithm used to compute the nearest neighbors:\n",
      " |  \n",
      " |      - 'ball_tree' will use :class:`BallTree`\n",
      " |      - 'kd_tree' will use :class:`KDTree`\n",
      " |      - 'brute' will use a brute-force search.\n",
      " |      - 'auto' will attempt to decide the most appropriate algorithm\n",
      " |        based on the values passed to :meth:`fit` method.\n",
      " |  \n",
      " |      Note: fitting on sparse input will override the setting of\n",
      " |      this parameter, using brute force.\n",
      " |  \n",
      " |  leaf_size : int, default=30\n",
      " |      Leaf size passed to BallTree or KDTree.  This can affect the\n",
      " |      speed of the construction and query, as well as the memory\n",
      " |      required to store the tree.  The optimal value depends on the\n",
      " |      nature of the problem.\n",
      " |  \n",
      " |  p : int, default=2\n",
      " |      Power parameter for the Minkowski metric. When p = 1, this is\n",
      " |      equivalent to using manhattan_distance (l1), and euclidean_distance\n",
      " |      (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
      " |  \n",
      " |  metric : str or callable, default='minkowski'\n",
      " |      Metric to use for distance computation. Default is \"minkowski\", which\n",
      " |      results in the standard Euclidean distance when p = 2. See the\n",
      " |      documentation of `scipy.spatial.distance\n",
      " |      <https://docs.scipy.org/doc/scipy/reference/spatial.distance.html>`_ and\n",
      " |      the metrics listed in\n",
      " |      :class:`~sklearn.metrics.pairwise.distance_metrics` for valid metric\n",
      " |      values.\n",
      " |  \n",
      " |      If metric is \"precomputed\", X is assumed to be a distance matrix and\n",
      " |      must be square during fit. X may be a :term:`sparse graph`, in which\n",
      " |      case only \"nonzero\" elements may be considered neighbors.\n",
      " |  \n",
      " |      If metric is a callable function, it takes two arrays representing 1D\n",
      " |      vectors as inputs and must return one value indicating the distance\n",
      " |      between those vectors. This works for Scipy's metrics, but is less\n",
      " |      efficient than passing the metric name as a string.\n",
      " |  \n",
      " |  metric_params : dict, default=None\n",
      " |      Additional keyword arguments for the metric function.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of parallel jobs to run for neighbors search.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |      Doesn't affect :meth:`fit` method.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  classes_ : array of shape (n_classes,)\n",
      " |      Class labels known to the classifier\n",
      " |  \n",
      " |  effective_metric_ : str or callble\n",
      " |      The distance metric used. It will be same as the `metric` parameter\n",
      " |      or a synonym of it, e.g. 'euclidean' if the `metric` parameter set to\n",
      " |      'minkowski' and `p` parameter set to 2.\n",
      " |  \n",
      " |  effective_metric_params_ : dict\n",
      " |      Additional keyword arguments for the metric function. For most metrics\n",
      " |      will be same with `metric_params` parameter, but may also contain the\n",
      " |      `p` parameter value if the `effective_metric_` attribute is set to\n",
      " |      'minkowski'.\n",
      " |  \n",
      " |  n_features_in_ : int\n",
      " |      Number of features seen during :term:`fit`.\n",
      " |  \n",
      " |      .. versionadded:: 0.24\n",
      " |  \n",
      " |  feature_names_in_ : ndarray of shape (`n_features_in_`,)\n",
      " |      Names of features seen during :term:`fit`. Defined only when `X`\n",
      " |      has feature names that are all strings.\n",
      " |  \n",
      " |      .. versionadded:: 1.0\n",
      " |  \n",
      " |  n_samples_fit_ : int\n",
      " |      Number of samples in the fitted data.\n",
      " |  \n",
      " |  outputs_2d_ : bool\n",
      " |      False when `y`'s shape is (n_samples, ) or (n_samples, 1) during fit\n",
      " |      otherwise True.\n",
      " |  \n",
      " |  See Also\n",
      " |  --------\n",
      " |  RadiusNeighborsClassifier: Classifier based on neighbors within a fixed radius.\n",
      " |  KNeighborsRegressor: Regression based on k-nearest neighbors.\n",
      " |  RadiusNeighborsRegressor: Regression based on neighbors within a fixed radius.\n",
      " |  NearestNeighbors: Unsupervised learner for implementing neighbor searches.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  See :ref:`Nearest Neighbors <neighbors>` in the online documentation\n",
      " |  for a discussion of the choice of ``algorithm`` and ``leaf_size``.\n",
      " |  \n",
      " |  .. warning::\n",
      " |  \n",
      " |     Regarding the Nearest Neighbors algorithms, if it is found that two\n",
      " |     neighbors, neighbor `k+1` and `k`, have identical distances\n",
      " |     but different labels, the results will depend on the ordering of the\n",
      " |     training data.\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/K-nearest_neighbor_algorithm\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> X = [[0], [1], [2], [3]]\n",
      " |  >>> y = [0, 0, 1, 1]\n",
      " |  >>> from sklearn.neighbors import KNeighborsClassifier\n",
      " |  >>> neigh = KNeighborsClassifier(n_neighbors=3)\n",
      " |  >>> neigh.fit(X, y)\n",
      " |  KNeighborsClassifier(...)\n",
      " |  >>> print(neigh.predict([[1.1]]))\n",
      " |  [0]\n",
      " |  >>> print(neigh.predict_proba([[0.9]]))\n",
      " |  [[0.666... 0.333...]]\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      KNeighborsClassifier\n",
      " |      sklearn.neighbors._base.KNeighborsMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.neighbors._base.NeighborsBase\n",
      " |      sklearn.base.MultiOutputMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, n_neighbors=5, *, weights='uniform', algorithm='auto', leaf_size=30, p=2, metric='minkowski', metric_params=None, n_jobs=None)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y)\n",
      " |      Fit the k-nearest neighbors classifier from the training dataset.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_samples, n_features) or                 (n_samples, n_samples) if metric='precomputed'\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : {array-like, sparse matrix} of shape (n_samples,) or                 (n_samples, n_outputs)\n",
      " |          Target values.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : KNeighborsClassifier\n",
      " |          The fitted k-nearest neighbors classifier.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict the class labels for the provided data.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      y : ndarray of shape (n_queries,) or (n_queries, n_outputs)\n",
      " |          Class labels for each data sample.\n",
      " |  \n",
      " |  predict_proba(self, X)\n",
      " |      Return probability estimates for the test data X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),                 or (n_queries, n_indexed) if metric == 'precomputed'\n",
      " |          Test samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      p : ndarray of shape (n_queries, n_classes), or a list of n_outputs                 of such arrays if n_outputs > 1.\n",
      " |          The class probabilities of the input samples. Classes are ordered\n",
      " |          by lexicographic order.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {'_parameter_constraints': <class 'dict'>}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  kneighbors(self, X=None, n_neighbors=None, return_distance=True)\n",
      " |      Find the K-neighbors of a point.\n",
      " |      \n",
      " |      Returns indices of and distances to the neighbors of each point.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed', default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors required for each sample. The default is the\n",
      " |          value passed to the constructor.\n",
      " |      \n",
      " |      return_distance : bool, default=True\n",
      " |          Whether or not to return the distances.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      neigh_dist : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Array representing the lengths to points, only present if\n",
      " |          return_distance=True.\n",
      " |      \n",
      " |      neigh_ind : ndarray of shape (n_queries, n_neighbors)\n",
      " |          Indices of the nearest points in the population matrix.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      In the following example, we construct a NearestNeighbors\n",
      " |      class from an array representing our data set and ask who's\n",
      " |      the closest point to [1,1,1]\n",
      " |      \n",
      " |      >>> samples = [[0., 0., 0.], [0., .5, 0.], [1., 1., .5]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=1)\n",
      " |      >>> neigh.fit(samples)\n",
      " |      NearestNeighbors(n_neighbors=1)\n",
      " |      >>> print(neigh.kneighbors([[1., 1., 1.]]))\n",
      " |      (array([[0.5]]), array([[2]]))\n",
      " |      \n",
      " |      As you can see, it returns [[0.5]], and [[2]], which means that the\n",
      " |      element is at distance 0.5 and is the third element of samples\n",
      " |      (indexes start at 0). You can also query for multiple points:\n",
      " |      \n",
      " |      >>> X = [[0., 1., 0.], [1., 0., 1.]]\n",
      " |      >>> neigh.kneighbors(X, return_distance=False)\n",
      " |      array([[1],\n",
      " |             [2]]...)\n",
      " |  \n",
      " |  kneighbors_graph(self, X=None, n_neighbors=None, mode='connectivity')\n",
      " |      Compute the (weighted) graph of k-Neighbors for points in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix} of shape (n_queries, n_features),             or (n_queries, n_indexed) if metric == 'precomputed', default=None\n",
      " |          The query point or points.\n",
      " |          If not provided, neighbors of each indexed point are returned.\n",
      " |          In this case, the query point is not considered its own neighbor.\n",
      " |          For ``metric='precomputed'`` the shape should be\n",
      " |          (n_queries, n_indexed). Otherwise the shape should be\n",
      " |          (n_queries, n_features).\n",
      " |      \n",
      " |      n_neighbors : int, default=None\n",
      " |          Number of neighbors for each sample. The default is the value\n",
      " |          passed to the constructor.\n",
      " |      \n",
      " |      mode : {'connectivity', 'distance'}, default='connectivity'\n",
      " |          Type of returned matrix: 'connectivity' will return the\n",
      " |          connectivity matrix with ones and zeros, in 'distance' the\n",
      " |          edges are distances between points, type of distance\n",
      " |          depends on the selected metric parameter in\n",
      " |          NearestNeighbors class.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      A : sparse-matrix of shape (n_queries, n_samples_fit)\n",
      " |          `n_samples_fit` is the number of samples in the fitted data.\n",
      " |          `A[i, j]` gives the weight of the edge connecting `i` to `j`.\n",
      " |          The matrix is of CSR format.\n",
      " |      \n",
      " |      See Also\n",
      " |      --------\n",
      " |      NearestNeighbors.radius_neighbors_graph : Compute the (weighted) graph\n",
      " |          of Neighbors for points in X.\n",
      " |      \n",
      " |      Examples\n",
      " |      --------\n",
      " |      >>> X = [[0], [3], [1]]\n",
      " |      >>> from sklearn.neighbors import NearestNeighbors\n",
      " |      >>> neigh = NearestNeighbors(n_neighbors=2)\n",
      " |      >>> neigh.fit(X)\n",
      " |      NearestNeighbors(n_neighbors=2)\n",
      " |      >>> A = neigh.kneighbors_graph(X)\n",
      " |      >>> A.toarray()\n",
      " |      array([[1., 0., 1.],\n",
      " |             [0., 1., 1.],\n",
      " |             [1., 0., 1.]])\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.neighbors._base.KNeighborsMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for `X`.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of ``self.predict(X)`` wrt. `y`.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : dict\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as :class:`~sklearn.pipeline.Pipeline`). The latter have\n",
      " |      parameters of the form ``<component>__<parameter>`` so that it's\n",
      " |      possible to update each component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : estimator instance\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# detail information about KNeighborsClassifier\n",
    "help(KNeighborsClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aec5bb62",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
